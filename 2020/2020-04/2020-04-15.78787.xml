<?xml version="1.0" encoding="UTF-8"?>
<messages xmlns="https://www.news.admin.ch/messages" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.0">
  <message id="78787" revoked="no">
    <version>1</version>
    <pubdate>2020-04-15</pubdate>
    <type>Memorandum</type>
    <originator department-msg="no" id="323" lead="yes" topnews="no">
      <department-id>701</department-id>
      <name lang="de">Eidg. Materialprüfungs- und Forschungsanstalt</name>
      <name lang="fr">Laboratoire fédéral d'essai des matériaux et de recherche</name>
      <name lang="it">Laboratorio federale di prova dei materiali e di ricerca</name>
      <name lang="en">Federal Laboratory for Materials Testing and Research</name>
      <www lang="de">http://www.empa.ch</www>
      <www lang="fr">http://www.empa.ch</www>
      <www lang="it">http://www.empa.ch</www>
      <www lang="en">http://www.empa.ch</www>
      <email lang="de">contact@empa.ch</email>
      <email lang="fr">contact@empa.ch</email>
      <email lang="it">contact@empa.ch</email>
      <email lang="en">contact@empa.ch</email>
    </originator>
    <department id="701">
      <name lang="de">Eidgenössisches Departement für Wirtschaft, Bildung und Forschung</name>
      <name lang="fr">Département fédéral de l'économie, de la formation et de la recherche</name>
      <name lang="it">Dipartimento federale dell'economia, della formazione e della ricerca</name>
      <name lang="en">Federal Department of Economic Affairs, Education and Research</name>
      <www lang="de">http://www.wbf.admin.ch</www>
      <www lang="fr">http://www.wbf.admin.ch</www>
      <www lang="it">http://www.wbf.admin.ch</www>
      <www lang="en">http://www.wbf.admin.ch</www>
      <email lang="de">info@gs-wbf.admin.ch</email>
      <email lang="fr">info@gs-wbf.admin.ch</email>
      <email lang="it">info@gs-wbf.admin.ch</email>
      <email lang="en">info@gs-wbf.admin.ch</email>
    </department>
    <content lang="de">
      <city>Dübendorf, St. Gallen und Thun</city>
      <title>Wenn Algorithmen für uns entscheiden</title>
      <lead>Künstliche Intelligenz (KI) wird immer leistungsfähiger und für immer komplexere Aufgaben eingesetzt. Das wirft ethische Fragen auf, etwa wenn mit Hilfe von KI für Menschen entschieden oder über sie geurteilt wird. Ein Team der Empa war massgeblich an einer neuen Studie der TA-SWISS beteiligt, in der Chancen und Risiken der KI für die Gesellschaft untersucht wurden und die am 15. April 2020 der Öffentlichkeit vorgestellt wurde.</lead>
      <text link="no">&lt;p&gt;Künstliche Intelligenz ist ein sehr leistungsfähiges Werkzeug zur Lösung komplexer Probleme und zur Bewältigung riesiger Mengen an unsortierten Daten. Ihr Einsatz erlaubt es, Sprachen weit besser zu übersetzen als zuvor oder menschliche Gegner in Strategiespielen aller Art zu bezwingen. Stetig wird die KI verbessert und für immer mehr Tätigkeiten eingesetzt, die bisher Menschen vorbehalten waren, etwa um Steuerbetrug zu identifizieren oder Krankheiten zu diagnostizieren. &lt;/p&gt; &lt;h3&gt;Vertrauen ist gut, Kontrolle ist besser&lt;/h3&gt;&lt;p&gt; Doch rapide wachsende technische Fähigkeiten brauchen ein wachsames Auge für die Risiken, die damit einhergehen können. Kann KI etwa massenweise Jobs kosten? Wie ändert sich unser Konsumverhalten, wenn immer mehr Menschen den Kaufempfehlungen einer intelligenten Suchmaschine folgen? Was geschieht mit unseren Medien, wenn KI zur Fabrikation von "Fake News" beiträgt oder ideologische Filterblasen nicht etwa auflöst, sondern sogar ausbaut und verstärkt? Was kann geschehen, wenn die Staatsgewalt KI einsetzt, um vorausschauende Polizeiarbeit zu betreiben, Verordnungen zu erlassen oder die Arbeitsbelastung bei Gerichten zu verringern? Wie soll Forschung und Bildung auf die Chancen und Risiken von KI reagieren und welche Kompetenzen sind besonders für heutige Forschende und zukünftige Entscheidungsträger relevant, um KI für die Gesellschaft bestmöglich zu nutzen?&lt;br /&gt; Diese und ähnliche Fragen wurden in der TA-SWISS-Studie von einem interdisziplinären Projektteam unter der Leitung von Markus Christen von der "Digital Society Initiative" der Universität Zürich, den Empa-Forschern Clemens Mader, Lorenz Hilty und Claudia Som sowie Johann Čas vom Institut für Technikfolgenabschätzung der Österreichische Akademie der Wissenschaften durchgeführt. Die Forscherinnen und Forscher erarbeiteten ihre Ergebnisse mit Hilfe von Methoden wie etwa gezieltem Literaturstudium, Workshops und Befragungen von mehr als 300 internationalen Experten. &lt;/p&gt; &lt;h3&gt;Handlungsanweisungen für die Politik&lt;/h3&gt;&lt;p&gt; Aus diesen Arbeiten resultieren neun Empfehlungen für verschiedene Bereiche wie Arbeit, Bildung und Forschung, Konsum, Medien und Verwaltung. Im Bereich der Bildung etwa sei es wichtig, Fachleute nicht nur zum Entwickeln und implementieren von KI-Systemen zu befähigen, sondern zugleich die Urteilsfähigkeit über rechtliche, ethische und soziale Auswirkungen der KI zu fördern. In Bereichen mit unklarer Risikolage sollte die Forschung zur Erkennung solcher Risiken intensiviert werden, fordern die Studienautoren. Zu diesem Zweck sei eine Finanzierung seitens der Hochschulen oder über Drittmittelförderung wünschenswert.&lt;br /&gt; Die Expertinnen und Experten äussern sich in der TA-Swiss-Studie auch zur mangelnden Transparenz der KI und ihren möglichen diskriminierenden Eigenschaften. Mögliche Kontrollmechanismen für diese Systeme werden diskutiert, ebenso wie rechtliche Aspekte, die aus der Nutzung von KI hervorgehen, etwa zur Haftung oder zum Datenschutz. &lt;/p&gt; </text>
      <contact>Dr. Clemens Mader Empa, Technology and Society Phone +41 58 765 73 59 clemens.mader@empa.ch Dr. Patrick Wäger Empa, Technology and Society Phone +41 58 765 78 45 patrick.waeger@empa.ch Redaktion / Medienkontakt Rainer Klose Empa, Communications Phone +41 58 765 47 33 redaktion@empa.ch</contact>
      <link id="199987">
        <title>Empa Medienmitteilung</title>
        <uri>https://www.empa.ch/web/s604/ta-swiss-ki-studie</uri>
        <position>Context</position>
      </link>
      <link id="199988">
        <title>TA-SWISS Projektseite (DE / EN / FR)</title>
        <uri>https://www.ta-swiss.ch/themen-projekte-publikationen/informationsgesellschaft/kuenstliche-intelligenz/</uri>
        <position>Context</position>
      </link>
      <revisions> </revisions>
    </content>
    <content lang="fr">
      <city>Dübendorf, St. Gallen und Thun</city>
      <title>Quand les algorithmes décident pour nous</title>
      <lead>L'intelligence artificielle (IA) devient de plus en plus puissante et est utilisée pour des tâches de plus en plus complexes. Cela soulève des questions éthiques, par exemple lorsque l'IA est utilisée pour prendre des déci-sions pour des personnes ou pour les juger. Une équipe de l'Empa a été fortement impliquée dans une nou-velle étude de TA-SWISS qui a examiné les opportunités et les risques de l'IA pour la société. L'étude, intitulée "Quand les algorithmes décident pour nous : Les opportunités et les risques de l'intelligence artificielle" a été présenté au public le 15 avril 2020.</lead>
      <text link="no"> L'intelligence artificielle est un outil très puissant pour résoudre des problèmes complexes et traiter d'énormes quantités de données non triées. Son utilisation permet de traduire des langues mieux que jamais ou de vaincre des adversaires humains dans des jeux de stratégie de toutes sortes. L'IA est constamment améliorée et utilisée pour de plus en plus d'activités qui étaient auparavant réservées aux humains, comme l'identification de la fraude fiscale ou le diagnostic de maladies. &lt;br /&gt;La confiance, c'est bien, le contrôle, c'est mieux &lt;br /&gt;Mais les capacités techniques en pleine croissance nécessitent un œil attentif aux risques qu'elles comportent. L'IA peut-elle coûter beaucoup d'emplois ? Comment notre comportement de consommateur changera-t-il si de plus en plus de personnes suivent les recommandations d'achat d'un moteur de recherche intelligent ? Qu'ar-rive-t-il à nos médias si l'IA contribue à la production de fausses nouvelles ou ne dissout pas les bulles de fil-trage idéologiques, mais les élargit et les renforce ? Que peut-il se passer si l'État utilise l'IA, par exemple pour effectuer un travail de police proactif, émettre des règlements ou réduire la charge de travail des tribunaux ? Comment la recherche et l'éducation devraient-elles réagir aux opportunités et aux risques de l'IA et quelles compétences sont particulièrement pertinentes pour les chercheurs d'aujourd'hui et les décideurs de demain afin de faire le meilleur usage possible de l'IA pour la société ? &lt;br /&gt;Ces questions et d'autres questions similaires ont été abordées dans l'étude TA-SWISS par une équipe de projet interdisciplinaire dirigée par Markus Christen (Digital Society Initiative, Université de Zurich), Clemens Mader, Lorenz Hilty, Claudia Som (Laboratoire Technologie et société, Empa) et Johann Čas (Institut d'évaluation de la technologie, Académie autrichienne des sciences). Les chercheurs ont élaboré leurs résultats en utilisant des méthodes telles que des études bibliographiques ciblées, des ateliers et des entretiens avec plus de 300 experts internationaux. &lt;br /&gt;Instructions pour les décideurs politiques &lt;br /&gt;Ce travail a abouti à neuf recommandations pour les domaines du travail: les domaines de l'éducation et de la recherche, de la consommation, des médias et de l'administration. Dans le domaine de l'éducation, par exemple, il est important non seulement de permettre aux experts de développer et de mettre en œuvre des systèmes d'IA, mais aussi de promouvoir la capacité à juger les effets juridiques, éthiques et sociaux de l'IA. Dans les domaines où la situation des risques n'est pas claire, les experts demandent que la recherche visant à identifier ces risques soit intensifiée. À cette fin, un soutien financier des universités ou par le biais de fonds de tiers est souhaitable.&lt;br /&gt;Les experts commentent également dans l'étude de TA-Swiss le manque de transparence de l'IA et ses éven-tuelles caractéristiques discriminatoires. Les mécanismes de contrôle possibles pour ces systèmes sont examinés, ainsi que les aspects juridiques découlant de l'utilisation de l'IA, tels que la responsabilité ou la protection des données. </text>
      <contact>Dr. Clemens Mader Empa, Technology and Society Tél +41 58 765 73 59 clemens.mader@empa.ch Dr. Patrick Wäger Empa, Technology and Society Tél +41 58 765 78 45 patrick.waeger@empa.ch</contact>
      <link id="199987">
        <title>Empa Medienmitteilung</title>
        <uri>https://www.empa.ch/web/s604/ta-swiss-ki-studie</uri>
        <position>Context</position>
      </link>
      <link id="199988">
        <title>TA-SWISS Projektseite (DE / EN / FR)</title>
        <uri>https://www.ta-swiss.ch/themen-projekte-publikationen/informationsgesellschaft/kuenstliche-intelligenz/</uri>
        <position>Context</position>
      </link>
      <revisions> </revisions>
    </content>
    <content lang="en">
      <city>Dübendorf, St. Gallen und Thun</city>
      <title>When algorithms decide for us</title>
      <lead>Artificial intelligence (AI) is becoming more powerful and is used for increasingly complex tasks. This raises ethical questions, for instance, when AI is used to make decisions for or judge people. A team of Empa researchers was involved in a new TA-SWISS study, which examined the opportunities and risks of AI for society. The study results were made public on 15 April 2020.</lead>
      <text link="no">Artificial intelligence is a very powerful tool for solving complex problems and handling huge amounts of random data. Its use allows to translate languages far better than ever before or to defeat human opponents in strategy games of various kinds. AI is constantly being improved and used for more and more activities that could previously be performed only by humans, such as identifying tax fraud or diagnosing diseases. Confidence is good, but supervision is better But rapidly growing technical capabilities require a watchful eye for the risks that accompany them. Can AI create mass job losses? How will our consumer behavior change if more and more people follow shopping recommendations of a smart search engine? What happens to our media if AI contributes to the production of fake news or does not dissolve ideological filter bubbles, but rather expands and reinforces them? What can happen if the government uses AI, for example to carry out predictive policing, to issue regulations or to reduce the workload at courts? How should research and education react to the opportunities and risks of AI and which competences are particularly relevant for today's researchers and future decision makers in order to make the best possible use of AI for society? These and similar questions were addressed in the TA-SWISS study by an interdisciplinary project team led by Markus Christen (Digital Society Initiative, University of Zurich), the Empa researchers Clemens Mader, Claudia Som and Lorenz Hilty and Johann Čas (Institute for Technology Assessment, Austrian Academy of Sciences). The researchers drew up their results using methods such as targeted literature studies, workshops and interviews with more than 300 international experts. Recommendations for research, education and policy This work has resulted in nine recommendations for the sectors examined: work, education and research, consumption, media and administration. In the educational sector, for example, it is important not only to enable experts to develop and implement AI systems, but also to build competences to judge the legal, ethical and social effects of AI. In sectors where the risk level is unknown, the experts demand that more research should be done to identify such risks. For this purpose, funding from universities or through third-party funding would be desirable. The experts also comment on the lack of transparency of AI and its possible discriminatory characteristics. Potential control mechanisms for these systems are discussed, as are legal aspects arising from the use of AI, such as liability or data protection. </text>
      <contact>Dr. Clemens Mader Empa, Technology and Society Phone +41 58 765 73 59 clemens.mader@empa.ch Dr. Patrick Wäger Empa, Technology and Society Phone +41 58 765 78 45 patrick.waeger@empa.ch</contact>
      <link id="199987">
        <title>Empa Medienmitteilung</title>
        <uri>https://www.empa.ch/web/s604/ta-swiss-ki-studie</uri>
        <position>Context</position>
      </link>
      <link id="199988">
        <title>TA-SWISS Projektseite (DE / EN / FR)</title>
        <uri>https://www.ta-swiss.ch/themen-projekte-publikationen/informationsgesellschaft/kuenstliche-intelligenz/</uri>
        <position>Context</position>
      </link>
      <revisions> </revisions>
    </content>
    <topics>
      <topic id="8">
        <name lang="de">Bildung und Forschung</name>
        <name lang="fr">Formation et recherche</name>
        <name lang="it">Formazione e ricerca</name>
        <name lang="en">Education and Research</name>
      </topic>
      <topic id="36">
        <name lang="de">Informatik und E-Government</name>
        <name lang="fr">Informatique et cyberadministration</name>
        <name lang="it">Informatica ed e-government</name>
        <name lang="en">IT and E-Government</name>
      </topic>
      <topic id="45">
        <name lang="de">Technologie</name>
        <name lang="fr">Technologie</name>
        <name lang="it">Tecnologia</name>
        <name lang="en">Technology</name>
      </topic>
    </topics>
  </message>
</messages>
